{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d986cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.spatial.distance import mahalanobis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caa935f",
   "metadata": {},
   "source": [
    "# Week 5 Coding Quiz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5caa7bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty</th>\n",
       "      <th>speed</th>\n",
       "      <th>accident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.676866</td>\n",
       "      <td>6.669184</td>\n",
       "      <td>0.318685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.634571</td>\n",
       "      <td>6.626761</td>\n",
       "      <td>0.496661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.107245</td>\n",
       "      <td>21.476106</td>\n",
       "      <td>0.496126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.144006</td>\n",
       "      <td>15.749975</td>\n",
       "      <td>0.196447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030893</td>\n",
       "      <td>14.013525</td>\n",
       "      <td>0.661416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   difficulty      speed  accident\n",
       "0    0.676866   6.669184  0.318685\n",
       "1    0.634571   6.626761  0.496661\n",
       "2    0.107245  21.476106  0.496126\n",
       "3    0.144006  15.749975  0.196447\n",
       "4    0.030893  14.013525  0.661416"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to create data for this question \n",
    "num = 100000 \n",
    " \n",
    "difficulty = np.random.uniform(0, 1, (num,)) \n",
    " \n",
    "speed = np.maximum(np.random.normal(15, 5, (num, )) - difficulty * 10, 0) \n",
    " \n",
    "accident = np.minimum(np.maximum(0.03 * speed + 0.4 * difficulty + np.random.normal(0, 0.3, (num,)), 0), 1) \n",
    " \n",
    "df = pd.DataFrame({'difficulty': difficulty, 'speed': speed, 'accident': accident}) \n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc98a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-9.663234560549936), np.float64(0.052062746858112914))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1\n",
    "def experiment(num=100000, seed=None):\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # same as the provided code for the quiz\n",
    "    difficulty = np.random.uniform(0, 1, (num,))\n",
    "    speed = np.maximum(np.random.normal(15, 5, (num, )) - difficulty * 10, 0) \n",
    "\n",
    "    # regress speed based on the on difficulty\n",
    "    X = sm.add_constant(difficulty)\n",
    "    model = sm.OLS(speed, X).fit()\n",
    "    # return the coefficient or whatever\n",
    "    return model.params[1]\n",
    "\n",
    "# run 500 experiments\n",
    "coeffs = [experiment(seed=i) for i in range(500)]\n",
    "\n",
    "# show the average, standard deviation of the coefficients\n",
    "np.mean(coeffs), np.std(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5cd781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-10.326134822154236), np.float64(0.044428368869339686))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 2\n",
    "\n",
    "def simulate_once(num=100000):\n",
    "    difficulty = np.random.uniform(0, 1, (num,))\n",
    "    speed = np.maximum(np.random.normal(15, 5, (num, )) - difficulty * 10, 0) \n",
    "    accident = np.minimum(np.maximum(0.03 * speed + 0.4 * difficulty + np.random.normal(0, 0.3, (num,)), 0), 1) \n",
    "    df = pd.DataFrame({'difficulty': difficulty, 'speed': speed, 'accident': accident})\n",
    "    \n",
    "    # regress speed on difficulty and likelihood of acccident\n",
    "    X = df[['difficulty', 'accident']]\n",
    "    y = df['speed']\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    return model.coef_[0]  # difficulty coefficient\n",
    "\n",
    "# run 500 times to get the average slope\n",
    "coeffs = [simulate_once() for _ in range(500)]\n",
    "\n",
    "# show the average, standard deviation of the coefficients\n",
    "np.mean(coeffs), np.std(coeffs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb98563",
   "metadata": {},
   "source": [
    "# Week 6 Coding Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b527d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_treated': 491,\n",
       " 'n_control': 509,\n",
       " 'ATE': 1.69527,\n",
       " 'ATT': 1.846409,\n",
       " 'ATU': 1.549477,\n",
       " 'OPT_effect_over_untreated_max': 2.17247}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and compute ATE, ATT, ATU, and \"optimal treatment effect\" per the prompt.\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"/Users/amit/Desktop/Current Classes/Y2S1 Experimental Design and Causality/DX702-mod-6/homework_6.1.csv\")\n",
    "\n",
    "# Expect columns: outcome Y, treatment X (0/1), confounder Z\n",
    "# Try to guess column names robustly\n",
    "cols = {c.lower(): c for c in df.columns}\n",
    "Y_col = cols.get(\"y\", None) or cols.get(\"outcome\", None) or list(df.columns)[0]\n",
    "X_col = cols.get(\"x\", None) or cols.get(\"treatment\", None) or list(df.columns)[1]\n",
    "Z_col = cols.get(\"z\", None) or cols.get(\"confounder\", None) or list(df.columns)[2]\n",
    "\n",
    "df = df[[Y_col, X_col, Z_col]].rename(columns={Y_col:\"Y\", X_col:\"X\", Z_col:\"Z\"}).copy()\n",
    "\n",
    "# Split groups\n",
    "treated = df[df[\"X\"] == 1].reset_index(drop=True)\n",
    "control = df[df[\"X\"] == 0].reset_index(drop=True)\n",
    "\n",
    "# Helper: fit 1-NN on Z arrays\n",
    "def nearest_index(src_Z, dst_Z):\n",
    "    # src_Z: array of shape (n_src, 1); dst_Z: (n_dst, 1)\n",
    "    nn = NearestNeighbors(n_neighbors=1, metric=\"euclidean\")\n",
    "    nn.fit(dst_Z)\n",
    "    distances, indices = nn.kneighbors(src_Z, return_distance=True)\n",
    "    return indices.ravel()\n",
    "\n",
    "# For each treated unit, find nearest control by Z\n",
    "t_to_c_idx = nearest_index(treated[[\"Z\"]].values, control[[\"Z\"]].values)\n",
    "treated_matches = control.iloc[t_to_c_idx].reset_index(drop=True)\n",
    "\n",
    "# For each control unit, find nearest treated by Z\n",
    "c_to_t_idx = nearest_index(control[[\"Z\"]].values, treated[[\"Z\"]].values)\n",
    "control_matches = treated.iloc[c_to_t_idx].reset_index(drop=True)\n",
    "\n",
    "# Individual effects:\n",
    "# For treated i: tau_i = Y_treated_i - Y_matched_control_i\n",
    "tau_treated = treated[\"Y\"].values - treated_matches[\"Y\"].values\n",
    "\n",
    "# For control j: tau_j = Y_matched_treated_j - Y_control_j\n",
    "tau_control = control_matches[\"Y\"].values - control[\"Y\"].values\n",
    "\n",
    "# ATE: average over *all items* using their nearest opposite-group counterfactual\n",
    "ATE = np.mean(np.concatenate([tau_treated, tau_control]))\n",
    "\n",
    "# ATT: average over treated only\n",
    "ATT = np.mean(tau_treated)\n",
    "\n",
    "# ATU: average over untreated only\n",
    "ATU = np.mean(tau_control)\n",
    "\n",
    "# \"Optimal treatment effect\": maximum treatment effect across all untreated items\n",
    "# i.e., consider only untreated items' tau and take max\n",
    "OPT = np.max(tau_control)\n",
    "\n",
    "# Round for display\n",
    "def r(x): \n",
    "    return float(np.round(x, 6))\n",
    "\n",
    "results = {\n",
    "    \"n_treated\": int(len(treated)),\n",
    "    \"n_control\": int(len(control)),\n",
    "    \"ATE\": r(ATE),\n",
    "    \"ATT\": r(ATT),\n",
    "    \"ATU\": r(ATU),\n",
    "    \"OPT_effect_over_untreated_max\": r(OPT),\n",
    "}\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1811844f",
   "metadata": {},
   "source": [
    "# Week 7 Coding Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674493a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between X and residuals: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "\n",
    "# question data generation\n",
    "np.random.seed(0)\n",
    "W = np.random.normal(0, 1, (1000,))\n",
    "X = W + np.random.normal(0, 1, (1000,))\n",
    "Z = np.random.normal(0, 1, (1000,)) \n",
    "Y = X + Z + W + np.random.normal(0, 1, (1000,))\n",
    "\n",
    "# fit the linear model (Y ~ X + Z + W) and compute residuals\n",
    "X_mat = np.column_stack([np.ones(len(X)), X, Z, W])  # add intercept\n",
    "beta_hat = np.linalg.inv(X_mat.T @ X_mat) @ X_mat.T @ Y\n",
    "Y_hat = X_mat @ beta_hat\n",
    "residuals = Y - Y_hat\n",
    "\n",
    "# compute correlation between X and residuals (error term)\n",
    "corr = np.corrcoef(X, residuals)[0, 1]\n",
    "print(f\"Correlation between X and residuals: {corr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca55129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr(X, true error u=W+eps): 0.5090\n",
      "Corr(X, OLS residuals from Y~X+Z): -0.0000\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "\n",
    "# question data\n",
    "W = np.random.normal(0, 1, (1000,))\n",
    "X = W + np.random.normal(0, 1, (1000,))\n",
    "Z = np.random.normal(0, 1, (1000,))\n",
    "Y = X + Z + W + np.random.normal(0, 1, (1000,))\n",
    "\n",
    "eps = Y - (X + Z + W)\n",
    "u_true = W + eps\n",
    "corr_struct = np.corrcoef(X, u_true)[0, 1]\n",
    "print(f\"Corr(X, true error u=W+eps): {corr_struct:.4f}\")\n",
    "\n",
    "Xmat = np.column_stack([np.ones_like(X), X, Z])\n",
    "beta = np.linalg.inv(Xmat.T @ Xmat) @ (Xmat.T @ Y)\n",
    "Yhat = Xmat @ beta\n",
    "resid = Y - Yhat\n",
    "\n",
    "corr_resid = np.corrcoef(X, resid)[0, 1]\n",
    "print(f\"Corr(X, OLS residuals from Y~X+Z): {corr_resid:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ec62a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>W</th>\n",
       "      <th>Z</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.137055</td>\n",
       "      <td>1.221768</td>\n",
       "      <td>0.327829</td>\n",
       "      <td>1.944532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.112905</td>\n",
       "      <td>0.465835</td>\n",
       "      <td>0.599650</td>\n",
       "      <td>0.655514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.077755</td>\n",
       "      <td>1.795414</td>\n",
       "      <td>-0.063393</td>\n",
       "      <td>5.934411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.456373</td>\n",
       "      <td>-0.512159</td>\n",
       "      <td>1.177413</td>\n",
       "      <td>-0.188064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.012402</td>\n",
       "      <td>0.080002</td>\n",
       "      <td>-0.275697</td>\n",
       "      <td>-0.533775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>2.569934</td>\n",
       "      <td>1.233620</td>\n",
       "      <td>0.930467</td>\n",
       "      <td>6.188783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>0.190150</td>\n",
       "      <td>1.022164</td>\n",
       "      <td>-0.015151</td>\n",
       "      <td>0.697187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>-1.184465</td>\n",
       "      <td>-1.475929</td>\n",
       "      <td>-0.287056</td>\n",
       "      <td>-1.575303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>-0.121286</td>\n",
       "      <td>-0.914357</td>\n",
       "      <td>1.706237</td>\n",
       "      <td>-1.809819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>2.830207</td>\n",
       "      <td>0.825999</td>\n",
       "      <td>-1.154576</td>\n",
       "      <td>5.173403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         X         W         Z         Y\n",
       "0              0  1.137055  1.221768  0.327829  1.944532\n",
       "1              1 -0.112905  0.465835  0.599650  0.655514\n",
       "2              2  2.077755  1.795414 -0.063393  5.934411\n",
       "3              3  0.456373 -0.512159  1.177413 -0.188064\n",
       "4              4 -1.012402  0.080002 -0.275697 -0.533775\n",
       "...          ...       ...       ...       ...       ...\n",
       "9995        9995  2.569934  1.233620  0.930467  6.188783\n",
       "9996        9996  0.190150  1.022164 -0.015151  0.697187\n",
       "9997        9997 -1.184465 -1.475929 -0.287056 -1.575303\n",
       "9998        9998 -0.121286 -0.914357  1.706237 -1.809819\n",
       "9999        9999  2.830207  0.825999 -1.154576  5.173403\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/amit/Desktop/Current Classes/Y2S1 Experimental Design and Causality/DX702-mod-6/homework_7.1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b1d525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_X_from_interaction</th>\n",
       "      <th>beta_X_local(h=0.25)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W≈</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.396</td>\n",
       "      <td>1.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.893</td>\n",
       "      <td>1.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      beta_X_from_interaction  beta_X_local(h=0.25)\n",
       "W≈                                                 \n",
       "-1.0                    0.900                 0.902\n",
       " 0.0                    1.396                 1.418\n",
       " 1.0                    1.893                 1.920"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "# Compute beta_X at W≈-1,0,1 from homework_7.1.csv and summarize the trend\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(\"/Users/amit/Desktop/Current Classes/Y2S1 Experimental Design and Causality/DX702-mod-6/homework_7.1.csv\")[[\"X\", \"Y\",\"Z\",\"W\"]].dropna()\n",
    "\n",
    "def ols_beta_x(sub):\n",
    "    Xmat = np.column_stack([np.ones(len(sub)), sub[\"X\"].values, sub[\"Z\"].values])\n",
    "    yvec = sub[\"Y\"].values\n",
    "    b, *_ = np.linalg.lstsq(Xmat, yvec, rcond=None)\n",
    "    return b[1]\n",
    "\n",
    "targets = [-1.0, 0.0, 1.0]\n",
    "h = 0.25\n",
    "\n",
    "rows = []\n",
    "for w0 in targets:\n",
    "    mask = (df[\"W\"] >= w0 - h) & (df[\"W\"] <= w0 + h)\n",
    "    sub = df.loc[mask]\n",
    "    beta_x = ols_beta_x(sub) if len(sub) >= 5 else np.nan\n",
    "    rows.append({\"W≈\": w0, \"n\": len(sub), \"beta_X_local(h=0.25)\": beta_x})\n",
    "\n",
    "# Global interaction check\n",
    "X_full = np.column_stack([\n",
    "    np.ones(len(df)),\n",
    "    df[\"X\"].values,\n",
    "    df[\"Z\"].values,\n",
    "    df[\"W\"].values,\n",
    "    (df[\"X\"]*df[\"W\"]).values,\n",
    "    (df[\"Z\"]*df[\"W\"]).values,\n",
    "])\n",
    "y_full = df[\"Y\"].values\n",
    "b, *_ = np.linalg.lstsq(X_full, y_full, rcond=None)\n",
    "b0,bX,bZ,bW,bXW,bZW = b\n",
    "\n",
    "for w0 in targets:\n",
    "    rows.append({\"W≈\": w0, \"n\": len(df), \"beta_X_local(h=0.25)\": np.nan,\n",
    "                 \"beta_X_from_interaction\": bX + bXW*w0})\n",
    "\n",
    "out = pd.DataFrame(rows)\n",
    "\n",
    "# Pivot for readability\n",
    "pivot = out.pivot_table(index=\"W≈\", values=[\"beta_X_local(h=0.25)\",\"beta_X_from_interaction\"], aggfunc=\"mean\")\n",
    "pivot_rounded = pivot.round(3)\n",
    "pivot_rounded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a85a10eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr_const</th>\n",
       "      <th>sd_beta_hat (i)</th>\n",
       "      <th>mean_SE_hat (ii)</th>\n",
       "      <th>ratio (i)/(ii)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>1.0735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>1.2823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0448</td>\n",
       "      <td>2.2195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corr_const  sd_beta_hat (i)  mean_SE_hat (ii)  ratio (i)/(ii)\n",
       "0         0.2           0.0480            0.0447          1.0735\n",
       "1         0.5           0.0576            0.0449          1.2823\n",
       "2         0.8           0.0993            0.0448          2.2195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 4\n",
    "# Simulation to study effect of serial correlation strength on beta_X variability vs. its OLS SE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def make_error(corr_const, num, rng):\n",
    "    \"\"\"AR(1)-style error with parameter corr_const and unit-variance innovations.\"\"\"\n",
    "    out = np.empty(num, dtype=float)\n",
    "    prev = rng.normal(0, 1)\n",
    "    for i in range(num):\n",
    "        prev = corr_const * prev + (1 - corr_const) * rng.normal(0, 1)\n",
    "        out[i] = prev\n",
    "    return out\n",
    "\n",
    "def ols_beta_and_se(y, x):\n",
    "    \"\"\"Return beta1 and its conventional SE from OLS of y ~ 1 + x.\"\"\"\n",
    "    n = len(x)\n",
    "    X = np.column_stack([np.ones(n), x])\n",
    "    # OLS via normal equations\n",
    "    XtX = X.T @ X\n",
    "    XtX_inv = np.linalg.inv(XtX)\n",
    "    beta = XtX_inv @ (X.T @ y)\n",
    "    resid = y - X @ beta\n",
    "    dof = n - X.shape[1]\n",
    "    sigma2 = (resid @ resid) / dof\n",
    "    se = np.sqrt(sigma2 * XtX_inv[1, 1])  # SE for beta_x\n",
    "    return beta[1], se\n",
    "\n",
    "def run_trials(rho, n=500, trials=800):\n",
    "    betas = np.empty(trials)\n",
    "    ses = np.empty(trials)\n",
    "    for t in range(trials):\n",
    "        eps_x = make_error(rho, n, rng)\n",
    "        eps_y = make_error(rho, n, rng)  # independent of eps_x innovations\n",
    "        X = 0.5 + eps_x\n",
    "        beta_true = 1.0\n",
    "        Y = 2.0 + beta_true * X + eps_y\n",
    "        b1, se1 = ols_beta_and_se(Y, X)\n",
    "        betas[t] = b1\n",
    "        ses[t] = se1\n",
    "    sd_b = betas.std(ddof=1) # 1. empirical SD of beta_hat\n",
    "    mean_se = ses.mean() # 2. mean of estimated SE\n",
    "    ratio = sd_b / mean_se\n",
    "    return sd_b, mean_se, ratio\n",
    "\n",
    "results = []\n",
    "for rho in [0.2, 0.5, 0.8]:\n",
    "    sd_b, mean_se, ratio = run_trials(rho, n=500, trials=800)\n",
    "    results.append({\"corr_const\": rho, \"sd_beta_hat (i)\": sd_b, \"mean_SE_hat (ii)\": mean_se, \"ratio (i)/(ii)\": ratio})\n",
    "\n",
    "df_res = pd.DataFrame(results).round(4)\n",
    "df_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7b664",
   "metadata": {},
   "source": [
    "# Week 8 Coding Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03074e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propensity summary: min=0.0480, mean=0.4810, max=0.9322\n",
      "E[Y^1] (IPW) = 2.2010396833844457\n",
      "E[Y^0] (IPW) = -0.03821919617103208\n",
      "ATE (IPW)    = 2.2392588795554778\n",
      "Unweighted diff-in-means = 3.036626208813963\n",
      "Stabilized IPW ATE       = 2.274341189846216\n"
     ]
    }
   ],
   "source": [
    "# Q1 \n",
    "\n",
    "path = \"/Users/amit/Desktop/Current Classes/Y2S1 Experimental Design and Causality/DX702-mod-6/homework_8.1.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df2 = df.drop(columns=[c for c in df.columns if c.lower().startswith(\"unnamed\")], errors=\"ignore\").copy()\n",
    "\n",
    "# predict X from Zfor propensity model \n",
    "X_feat = df2[[\"Z\"]].values\n",
    "treat = df2[\"X\"].values\n",
    "\n",
    "# logistic regression\n",
    "logit = LogisticRegression(solver=\"lbfgs\")\n",
    "logit.fit(X_feat, treat)\n",
    "\n",
    "# predict propensity scores\n",
    "propensity = logit.predict_proba(X_feat)[:, 1]\n",
    "\n",
    "# avoid division by zero in weights\n",
    "eps = 1e-6\n",
    "p = np.clip(propensity, eps, 1 - eps)\n",
    "\n",
    "# IPW estimates\n",
    "Y = df2[\"Y\"].values\n",
    "Ey1 = np.mean((treat * Y) / p)            \n",
    "Ey0 = np.mean(((1 - treat) * Y) / (1 - p))\n",
    "ate_ipw = Ey1 - Ey0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "diff_means = df2.loc[df2[\"X\"]==1, \"Y\"].mean() - df2.loc[df2[\"X\"]==0, \"Y\"].mean()\n",
    "\n",
    "pi = treat.mean()\n",
    "sw_treated = pi / p\n",
    "sw_control = (1 - pi) / (1 - p)\n",
    "Ey1_sw = np.sum(sw_treated * treat * Y) / np.sum(sw_treated * treat + 1e-12)\n",
    "Ey0_sw = np.sum(sw_control * (1 - treat) * Y) / np.sum(sw_control * (1 - treat) + 1e-12)\n",
    "ate_sw = Ey1_sw - Ey0_sw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Propensity summary: min={:.4f}, mean={:.4f}, max={:.4f}\".format(p.min(), p.mean(), p.max()))\n",
    "print(\"E[Y^1] (IPW) =\", Ey1)\n",
    "print(\"E[Y^0] (IPW) =\", Ey0)\n",
    "print(\"ATE (IPW)    =\", ate_ipw)\n",
    "\n",
    "print(\"Unweighted diff-in-means =\", diff_means)\n",
    "print(\"Stabilized IPW ATE       =\", ate_sw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22bf94ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 propensities: [0.84011371 0.58464597 0.71108245]\n"
     ]
    }
   ],
   "source": [
    "# Q2 \n",
    "print(f\"First 3 propensities: {propensity[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cf48361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mahalanobis matching ATE (treated → nearest control, with replacement): 3.437678997912609\n"
     ]
    }
   ],
   "source": [
    "# Q3\n",
    "\n",
    "path = \"/Users/amit/Desktop/Current Classes/Y2S1 Experimental Design and Causality/DX702-mod-6/homework_8.2.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# clean\n",
    "df2 = df.drop(columns=[c for c in df.columns if c.lower().startswith(\"unnamed\")], errors=\"ignore\").copy()\n",
    "\n",
    "\n",
    "# Build inverse covariance from Z1, Z2\n",
    "if not {\"Z1\", \"Z2\", \"X\", \"Y\"}.issubset(df.columns):\n",
    "    raise ValueError(f\"Expected columns X, Y, Z1, Z2. Found: {list(df.columns)}\")\n",
    "Z = df[[\"Z1\", \"Z2\"]].copy()\n",
    "Z_rows = np.vstack([Z[\"Z1\"].values, Z[\"Z2\"].values])  \n",
    "cov_2x2 = np.cov(Z_rows)\n",
    "VI = np.linalg.inv(cov_2x2)\n",
    "\n",
    "\n",
    "\n",
    "# Match treated to nearest control (mahalanobis, with replacement)\n",
    "treated_idx = df.index[df[\"X\"] == 1].to_numpy()\n",
    "control_idx = df.index[df[\"X\"] == 0].to_numpy()\n",
    "\n",
    "Z_t = Z.loc[treated_idx].to_numpy()\n",
    "Z_c = Z.loc[control_idx].to_numpy()   # shape: n_c x 2\n",
    "\n",
    "Y_t = df.loc[treated_idx, \"Y\"].to_numpy()\n",
    "Y_c_all = df.loc[control_idx, \"Y\"].to_numpy()\n",
    "\n",
    "# For each treated point, find single nearest control by Mahalanobis distance\n",
    "match_control_indices = []\n",
    "for i in range(Z_t.shape[0]):\n",
    "    zi = Z_t[i]\n",
    "    # compute distances to all controls\n",
    "    dists = np.array([mahalanobis(zi, Z_c[j], VI) for j in range(Z_c.shape[0])])\n",
    "    j_best = np.argmin(dists)\n",
    "    match_control_indices.append(control_idx[j_best])\n",
    "\n",
    "matched_controls_y = df.loc[match_control_indices, \"Y\"].to_numpy()\n",
    "\n",
    "ate_match = float(np.mean(Y_t - matched_controls_y))\n",
    "print(\"Mahalanobis matching ATE (treated → nearest control, with replacement):\", ate_match)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc78948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst treated point (Z1, Z2): (2.6962240525635797, 0.5381554886023228)\n",
      "Max nearest-control Mahalanobis distance: 1.3830045328325054\n"
     ]
    }
   ],
   "source": [
    "# Q4\n",
    "df = df.drop(columns=[c for c in df.columns if c.lower().startswith(\"unnamed\")], errors=\"ignore\")\n",
    "\n",
    "# Expect columns: X (treatment), Y (outcome), Z1, Z2 (covariates)\n",
    "assert {\"X\",\"Z1\",\"Z2\"}.issubset(df.columns), f\"Expected columns X,Z1,Z2; found {df.columns.tolist()}\"\n",
    "\n",
    "Z = df[[\"Z1\", \"Z2\"]].copy()\n",
    "Z_rows = np.vstack([Z[\"Z1\"].values, Z[\"Z2\"].values])\n",
    "cov_2x2 = np.cov(Z_rows)\n",
    "VI = np.linalg.inv(cov_2x2)\n",
    "\n",
    "treated = df[df[\"X\"]==1].copy()\n",
    "control = df[df[\"X\"]==0].copy()\n",
    "\n",
    "Z_t = treated[[\"Z1\",\"Z2\"]].to_numpy()\n",
    "Z_c = control[[\"Z1\",\"Z2\"]].to_numpy()\n",
    "\n",
    "nearest_dist = []\n",
    "nearest_control_idx = []\n",
    "for i in range(Z_t.shape[0]):\n",
    "    zi = Z_t[i]\n",
    "    dists = np.array([mahalanobis(zi, Z_c[j], VI) for j in range(Z_c.shape[0])])\n",
    "    j_best = int(np.argmin(dists))\n",
    "    nearest_control_idx.append(j_best)\n",
    "    nearest_dist.append(float(dists[j_best]))\n",
    "\n",
    "nearest_dist = np.array(nearest_dist)\n",
    "worst_idx_local = int(np.argmax(nearest_dist))   # index within treated subset\n",
    "worst_treated_row = treated.iloc[worst_idx_local]\n",
    "\n",
    "worst_point = (float(worst_treated_row[\"Z1\"]), float(worst_treated_row[\"Z2\"]))\n",
    "worst_distance = float(nearest_dist[worst_idx_local])\n",
    "\n",
    "print(\"Worst treated point (Z1, Z2):\", worst_point)\n",
    "print(\"Max nearest-control Mahalanobis distance:\", worst_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb80653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
